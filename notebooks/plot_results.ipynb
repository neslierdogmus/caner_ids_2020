{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=150)\n",
    "plt.rc('font', size=8)\n",
    "\n",
    "def calculate_metrics(conf_mat, plot_num, keys):\n",
    "    mACC = np.zeros((plot_num,4,len(keys),5))\n",
    "    mPRE = np.zeros((plot_num,4,len(keys),5))\n",
    "    mREC = np.zeros((plot_num,4,len(keys),5))\n",
    "    mF1S = np.zeros((plot_num,4,len(keys),5))\n",
    "    mPRE_PC = np.zeros((plot_num,13,len(keys),5))\n",
    "    mREC_PC = np.zeros((plot_num,13,len(keys),5))\n",
    "    mF1S_PC = np.zeros((plot_num,13,len(keys),5))\n",
    "    CM15 = np.zeros((plot_num,15,15,len(keys),5))\n",
    "    CM13 = np.zeros((plot_num,13,13,len(keys),5))\n",
    "    for i in range(plot_num):\n",
    "        for k in range(len(keys)):\n",
    "            for fold in range(5):\n",
    "                cm15 = conf_mat[i][keys[k]][fold]\n",
    "                # merge web attacks\n",
    "                cm13 = np.vstack((cm15[0:12],sum(cm15[12:])))\n",
    "                cm13 = np.hstack((cm13[:,:12],np.expand_dims(np.sum(cm13[:,12:], axis=1),axis=1)))\n",
    "                CM15[i,:,:,k,fold] = cm15\n",
    "                CM13[i,:,:,k,fold] = cm13\n",
    "                # merge DoS attacks\n",
    "                cm11 = np.vstack((cm15[0:2],sum(cm15[2:7]),cm15[7:]))\n",
    "                cm11 = np.hstack((cm11[:,:2],np.expand_dims(np.sum(cm11[:,2:7], axis=1),axis=1),cm11[:,7:]))\n",
    "                # merge both web and DoS attacks\n",
    "                cm09 = np.vstack((cm11[0:8],sum(cm11[8:])))\n",
    "                cm09 = np.hstack((cm09[:,:8],np.expand_dims(np.sum(cm09[:,8:], axis=1),axis=1)))\n",
    "                cm_array = [cm15, cm13, cm11, cm09]\n",
    "                for j in range(4):\n",
    "                    cm = cm_array[j]\n",
    "                    TN = cm[0,0]\n",
    "                    FN = sum(cm[1:,0])\n",
    "                    FP = sum(cm[0,1:])\n",
    "                    TP = sum(sum(cm[1:,1:]))\n",
    "\n",
    "                    mACC[i,j,k,fold] = sum(np.diag(cm)) / np.sum(cm) * 100\n",
    "                    mPRE[i,j,k,fold] = TP / (TP + FP) * 100\n",
    "                    mREC[i,j,k,fold] = TP / (TP + FN) * 100\n",
    "                    mF1S[i,j,k,fold] = 2*mPRE[i,j,k,fold]*mREC[i,j,k,fold]/(mPRE[i,j,k,fold]+mREC[i,j,k,fold])\n",
    "                for j in range(13):\n",
    "                    mPRE_PC[i,j,k,fold] = cm13[j,j]/sum(cm13[:,j]) * 100\n",
    "                    mREC_PC[i,j,k,fold] = cm13[j,j]/sum(cm13[j,:]) * 100\n",
    "                    mF1S_PC[i,j,k,fold] = 2*mPRE_PC[i,j,k,fold]*mREC_PC[i,j,k,fold]/(mPRE_PC[i,j,k,fold]+mREC_PC[i,j,k,fold])\n",
    "    print('ACC, PRE, REC, F1S and PRE_PC, REC_PC, F1S_PC are computed.')\n",
    "    return mACC, mPRE, mREC, mF1S, mPRE_PC, mREC_PC, mF1S_PC, CM15, CM13\n",
    "\n",
    "def print_tabular(*argv):\n",
    "    print(' \\\\\\\\\\n'.join([\" & \".join(map(lambda x:\"{:5.2f}\".format(x),line))\n",
    "    for line in argv])+' \\\\\\\\\\n')\n",
    "    \n",
    "def plot_accross_folds(metric, cm_num, ax, ylabel, plot_type, plot_num, xlabel=None, xticks=[], xticklabels=[], label=[]):\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    if not xlabel is None: ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_xticks(xticks)\n",
    "    ax.set_xticklabels(xticklabels)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax.grid(True, axis='y')\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    #ax._get_lines.get_next_color()\n",
    "    #colors = colors[1:]\n",
    "    for i in range(plot_num):\n",
    "        if plot_type == 'violin':\n",
    "            vp = ax.violinplot(metric[i,cm_num].T, positions = np.arange(1,len(keys)+1), showmeans=True)\n",
    "            ax.plot([1],[metric[i,cm_num,0,0]], color=colors[i], label=label[i] if label else None)\n",
    "        elif plot_type == 'meanline':\n",
    "            vp = ax.bar(np.arange(metric[i,cm_num].shape[0]),np.mean(metric[i,cm_num], axis=1), label=label[i] if label else None, alpha=0.8)\n",
    "            \n",
    "def calc_plot_kde(ax, metric, acc):\n",
    "    kde = KernelDensity(bandwidth=1.6, kernel='gaussian')\n",
    "    kde.fit(metric[:, None])\n",
    "\n",
    "    x = np.linspace(65, 103, 10000)\n",
    "    pdf_x = np.exp(kde.score_samples(x[:, None]))\n",
    "    pdf_x[x>100] = 0\n",
    "    pdf_x = pdf_x / np.trapz(pdf_x, x, dx=0.001)\n",
    "\n",
    "    ind = np.argwhere(x>=acc)[0,0]\n",
    "    print(np.trapz(pdf_x[ind:], x[ind:], dx=0.001))\n",
    "\n",
    "\n",
    "    ax.hist(metric, bins=15, density=True, rwidth=0.9, alpha=0.5, label='normalized histogram')\n",
    "    ax.plot(x, pdf_x, color='k', label='estimated density')\n",
    "    ax.plot(metric, np.full_like(metric, -0.001), '|k', markeredgewidth=1)\n",
    "    ax.plot([acc, acc], [0,pdf_x[ind]], '--', label='accuracy of top 9 features')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax.set_ylim(-0.005)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    order = [2,0,1]\n",
    "    ax.legend([handles[idx] for idx in order],[labels[idx] for idx in order], fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_path = '../results/Accuracies/Accuracies_complete/conf_matrix.npy'\n",
    "conf_mat = np.load(conf_mat_path, allow_pickle=True)\n",
    "keys = sorted(conf_mat[0].keys(), key=lambda x: -100*ord(x[0])+int(x[-1]))\n",
    "metrics_complete = calculate_metrics(conf_mat, 1, keys)\n",
    "\n",
    "conf_mat_path = '../results/Accuracies/Accuracies_uniform/conf_matrix.npy'\n",
    "conf_mat = np.load(conf_mat_path, allow_pickle=True)\n",
    "metrics_uniform = calculate_metrics(conf_mat, 2, keys)\n",
    "\n",
    "# ACC, PRE, REC, F1S and PRE_PC, REC_PC, F1S_PC\n",
    "metrics = [np.concatenate((metrics_complete[i], metrics_uniform[i]), axis=0) for i in range(len(metrics_complete))]\n",
    "\n",
    "keys = [key[:-1].upper()+'-'+key[-1] for key in keys]\n",
    "xticks = np.arange(1,len(keys)+1)\n",
    "xticklabels = [key.split('_')[-1].lstrip(\"0\") for key in keys]\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1,figsize=(12,10))\n",
    "plt.subplots_adjust(left=0.06, bottom=0.1, right=0.99, top=0.90)\n",
    "plot_accross_folds(metrics[0], 0, ax1, 'ACC-15', 'violin', 3)\n",
    "plot_accross_folds(metrics[1], 0, ax2, 'PRE', 'violin', 3)\n",
    "plot_accross_folds(metrics[2], 0, ax3, 'REC', 'violin', 3)\n",
    "plot_accross_folds(metrics[3], 0, ax4, 'F1S', 'violin', 3, xticks=xticks, xticklabels=xticklabels, label=['Experiment 1u', 'Experiment 2u', 'Experiment 2nu'])\n",
    "fig.legend(loc=1, prop={'size': 10})\n",
    "fig.savefig('analyze_models.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.options.display.float_format = '{:,.1f}'.format\n",
    "\n",
    "classes15 = ['BENIGN', 'Bot', 'DDoS', 'DoS GoldenEye', 'DoS Hulk', \n",
    "           'DoS Slowhttptest', 'DoS slowloris', 'FTP-Patator', 'Heartbleed',\n",
    "           'Infiltration', 'PortScan', 'SSH-Patator', 'Web Attack - Brute Force',\n",
    "           'Web Attack - Sql Injection', 'Web Attack - Xss', 'Average']\n",
    "\n",
    "classes13 = ['BENIGN', 'Bot', 'DDoS', 'DoS GoldenEye', 'DoS Hulk', \n",
    "           'DoS Slowhttptest', 'DoS slowloris', 'FTP-Patator', 'Heartbleed',\n",
    "           'Infiltration', 'PortScan', 'SSH-Patator',  \n",
    "           'Web Attack', 'Average']\n",
    "\n",
    "CM15 = np.sum(metrics[7][1,:,:,11,:],axis=-1).astype(int)\n",
    "CM13 = np.sum(metrics[8][1,:,:,11,:],axis=-1).astype(int)\n",
    "\n",
    "acc15 = np.mean(metrics[0][1,0,:,:],axis=-1)\n",
    "acc13 = np.mean(metrics[0][1,1,:,:],axis=-1)\n",
    "pre = np.mean(metrics[1][1,0,:,:],axis=-1)\n",
    "rec = np.mean(metrics[2][1,0,:,:],axis=-1)\n",
    "f1s = np.mean(metrics[3][1,0,:,:],axis=-1)\n",
    "\n",
    "# For 13-class\n",
    "pre_pc = np.mean(metrics[4][1,:,:,:],axis=-1)\n",
    "pre_pc = np.concatenate((pre_pc,[np.nanmean(pre_pc,axis=0)]),axis=0)\n",
    "rec_pc = np.mean(metrics[5][1,:,:,:],axis=-1)\n",
    "rec_pc = np.concatenate((rec_pc,[np.mean(rec_pc,axis=0)]),axis=0)\n",
    "f1s_pc = np.mean(metrics[6][1,:,:,:],axis=-1)\n",
    "f1s_pc = np.concatenate((f1s_pc,[np.mean(np.nan_to_num(f1s_pc),axis=0)]),axis=0)\n",
    "\n",
    "display(pd.DataFrame(data=CM15, index=classes15[:-1], columns=classes15[:-1]))\n",
    "display(pd.DataFrame(data=CM13, index=classes13[:-1], columns=classes13[:-1]))\n",
    "display(pd.DataFrame(data=[acc15,acc13,pre,rec,f1s], columns=keys, index=['ACC-15','ACC-13','PRE','REC','F1S']).transpose())\n",
    "display(pd.DataFrame(data=pre_pc, index=classes13))\n",
    "display(pd.DataFrame(data=rec_pc, index=classes13))\n",
    "display(pd.DataFrame(data=f1s_pc, index=classes13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_path = '../results/Accuracies/Accuracies_feature_analysis_1/conf_matrix.npy'\n",
    "conf_mat = np.load(conf_mat_path, allow_pickle=True)\n",
    "keys = sorted(conf_mat[0].keys(), key=lambda x: int(x.split('_')[1]))\n",
    "metrics1 = calculate_metrics(conf_mat, 1, keys)\n",
    "\n",
    "conf_mat_path = '../results/Accuracies/Accuracies_feature_analysis_2/conf_matrix.npy'\n",
    "conf_mat = np.load(conf_mat_path, allow_pickle=True)\n",
    "keys = sorted(conf_mat[0].keys(), key=lambda x: int(x.split('_')[1]))\n",
    "metrics2 = calculate_metrics(conf_mat, 1, keys)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1,figsize=(12,10))\n",
    "plt.subplots_adjust(left=0.06, bottom=0.1, right=0.99, top=0.90)\n",
    "ax1.set_xlim(-1,77)\n",
    "ax1.set_ylim(96.5,98.25)\n",
    "ax1.set_xlabel('Features', fontsize=12)\n",
    "baseline = np.mean(metrics_uniform[0][0,0,11])\n",
    "ax1.plot([-1,77],[baseline,baseline],'--k', label='mean ACC-15 with full feature set')\n",
    "plot_accross_folds(metrics1[0], 0, ax1, 'ACC-15', 'meanline', 1, xticks=np.arange(9,77,10), xticklabels=[str(i).zfill(2) for i in np.arange(10,78,10)], label=['mean ACC-15 with 76 features'])\n",
    "ax1.legend(loc=4, fontsize=12)\n",
    "\n",
    "ax2.set_xlim(-1,75)\n",
    "ax2.set_ylim(88,99)\n",
    "ax2.set_xlabel('Number of Features', fontsize=12)\n",
    "baseline = np.mean(metrics_uniform[0][0,0,11])\n",
    "ax2.plot([-1,77],[baseline,baseline],'--k', label='mean ACC-15 with full feature set')\n",
    "plot_accross_folds(metrics2[0], 0, ax2, 'ACC-15', 'meanline', 1, xticks=np.arange(7,77,10), xticklabels=[str(i).zfill(2) for i in np.arange(10,77,10)], label=['mean ACC-15 with increasing number of features'])\n",
    "ax2.legend(loc=4, fontsize=12)\n",
    "\n",
    "time_perf_path = '../results/Accuracies/Accuracies_feature_analysis_2/time_performance.npy'\n",
    "time_perf = np.load(time_perf_path, allow_pickle=True)[0]\n",
    "keys = sorted(time_perf.keys(), key=lambda x: int(x.split('_')[1]))\n",
    "\n",
    "test_indices = [np.load('../data/test_index1.npy'),\n",
    "                np.load('../data/test_index2.npy'),\n",
    "                np.load('../data/test_index3.npy'),\n",
    "                np.load('../data/test_index4.npy'),\n",
    "                np.load('../data/test_index5.npy')]\n",
    "\n",
    "test_len = np.array([len(test_set) for test_set in test_indices])\n",
    "\n",
    "time = np.zeros((75,1))\n",
    "for i in range(len(keys)):\n",
    "    time[i] = np.mean(time_perf[keys[i]] / test_len * 1e+06)\n",
    "ax3.plot(np.arange(3,78), time, '-k', label='average inference time per sample')\n",
    "ax3.legend(loc=4, fontsize=12)\n",
    "ax3.set_ylabel('Microseconds', fontsize=12)\n",
    "ax3.set_xlabel('Number of Features', fontsize=12)\n",
    "ax3.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax3.set_xlim(2,78)\n",
    "ax3.grid(True, axis='y')\n",
    "\n",
    "fig.savefig('analyze_features_1_2.pdf')\n",
    "\n",
    "print('3 features:', [np.mean(metrics2[i][0,0,0]) for i in range(4)], time[0])\n",
    "print('9 features:', [np.mean(metrics2[i][0,0,6]) for i in range(4)], time[6])\n",
    "print('77 features:', [np.mean(metrics2[i][0,0,74]) for i in range(4)], time[74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_path = '../results/Accuracies/Accuracies_feature_analysis_3/conf_matrix.npy'\n",
    "conf_mat = np.load(conf_mat_path, allow_pickle=True)\n",
    "keys = sorted(conf_mat[0].keys(), key=lambda x: int(x.split('_')[1]))\n",
    "metrics3 = calculate_metrics(conf_mat, 1, keys)\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1,figsize=(6,3))\n",
    "plt.subplots_adjust(left=0.065, bottom=0.1, right=0.99, top=0.90)\n",
    "calc_plot_kde(ax1, np.mean(metrics3[0][0,0], axis=-1), 97.58)\n",
    "print_tabular(np.mean(metrics3[0][0,0], axis=1))\n",
    "fig.savefig('analyze_features_3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
