{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from time import process_time \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "\n",
    "features = np.load('../data/features.npy')\n",
    "labels = np.load('../data/labels.npy', allow_pickle=True)\n",
    "\n",
    "test_indices = [np.load('../data/test_index1.npy'),\n",
    "                np.load('../data/test_index2.npy'),\n",
    "                np.load('../data/test_index3.npy'),\n",
    "                np.load('../data/test_index4.npy'),\n",
    "                np.load('../data/test_index5.npy')]\n",
    "\n",
    "extra_benign = np.load('../data/extra_benign.npy')\n",
    "\n",
    "# Experiment 1: removes one feature at each trial (77)\n",
    "# Experiment 2: starting from 3, add one feature at each trial (75)\n",
    "# Experiment 3: randomly selects 9 features at each trial (100)\n",
    "experiment_num = 3\n",
    "\n",
    "models_folder = '../results/Models/Models_feature_analysis_'+str(experiment_num)+'t'\n",
    "results_folder = '../results/Accuracies/Accuracies_feature_analysis_'+str(experiment_num)+'t'\n",
    "if not os.path.exists(models_folder): \n",
    "    os.mkdir(models_folder)\n",
    "    print('Models folder created as', models_folder)\n",
    "if not os.path.exists(results_folder): \n",
    "    os.mkdir(results_folder)\n",
    "    print('Results folder created as', results_folder)\n",
    "\n",
    "print('Index and data files loaded.')\n",
    "\n",
    "acc_path = os.path.join(results_folder, 'overall_accuracy.npy')\n",
    "conf_path = os.path.join(results_folder, 'conf_matrix.npy')\n",
    "cat_acc_path = os.path.join(results_folder, 'category_accuracy.npy')\n",
    "\n",
    "overall_accuracy = [{}, {}]\n",
    "conf_matrix = [{}, {}]\n",
    "category_accuracy = [{}, {}]\n",
    "\n",
    "if experiment_num == 1:\n",
    "    loop_range = range(1,78)\n",
    "    prefix = 'without_'\n",
    "elif experiment_num == 2:\n",
    "    loop_range = range(3,78)\n",
    "    sorted_indices = [22, 65, 43, 66, 4 , 33, 21, 41, 53, 74, 71, 37, 30, 12, 64, 6 , 63,\n",
    "                  76, 73, 18, 16, 17, 52, 0 , 70, 57,  7, 44, 11, 36, 59, 3 , 42, 34,\n",
    "                  32, 38, 75, 58, 45, 48, 49, 15, 54, 50,  9,  1, 19, 47, 51, 28, 72,\n",
    "                  25, 67, 20, 27, 24, 55, 10, 39, 2 , 60, 68, 56, 61, 69, 40, 8 , 35,\n",
    "                  5 , 23, 31, 46, 14, 62, 13, 26, 29]\n",
    "    tim_perf_path = os.path.join(results_folder, 'time_performance.npy')\n",
    "    time_performance = [{}, {}]\n",
    "    prefix = 'features_'\n",
    "elif experiment_num == 3:\n",
    "    loop_range = range(100)\n",
    "    prefix = 'trial_'\n",
    "else:\n",
    "    raise Exception('Experiment number can be 1, 2 or 3.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in loop_range:\n",
    "    for fold in range(1,6):\n",
    "        model_name = prefix + str(index).zfill(2)\n",
    "        model_folder = os.path.join(models_folder, model_name + '_' + str(fold))\n",
    "        model_file_path = os.path.join(model_folder, 'model.json')\n",
    "        weight_file_path = os.path.join(model_folder, 'weights.h5')\n",
    "        \n",
    "        mask = np.ones(len(labels), dtype=bool)\n",
    "        mask[test_indices[fold-1],] = False\n",
    "        mask[extra_benign,] = False;\n",
    "        if experiment_num == 1:\n",
    "            x_train = np.delete(features[mask], index-1, 1)\n",
    "            x_test_all = np.delete(features[~mask], index-1, 1)\n",
    "            x_test_uniform = np.delete(features[test_indices[fold-1],:], index-1, 1)\n",
    "        elif experiment_num == 2:\n",
    "            x_train = features[mask][:,sorted_indices[:index]]\n",
    "            x_test_all = features[~mask][:,sorted_indices[:index]]\n",
    "            x_test_uniform = features[test_indices[fold-1]][:,sorted_indices[:index]]\n",
    "            tp = None\n",
    "        elif experiment_num == 3:\n",
    "            features_path = os.path.join(model_folder, 'used_features.npy')\n",
    "            if os.path.exists(features_path):\n",
    "                random_indices = np.load(features_path)\n",
    "            else:\n",
    "                random_indices = np.random.choice(np.arange(77), 9, replace=False)\n",
    "            x_train = features[mask][:,random_indices]\n",
    "            x_test_all = features[~mask][:,random_indices]\n",
    "            x_test_uniform = features[test_indices[fold-1]][:,random_indices]\n",
    "        \n",
    "        minmax_scaler = preprocessing.MinMaxScaler()\n",
    "        x_train = minmax_scaler.fit_transform(x_train)\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        \n",
    "        y_train = labels[mask]\n",
    "        y_train = label_encoder.fit_transform(y_train)\n",
    "        one_hot_encoder = preprocessing.OneHotEncoder(sparse=False)\n",
    "        y_train = one_hot_encoder.fit_transform(y_train.reshape(-1,1))\n",
    "        \n",
    "        if os.path.exists(model_file_path): \n",
    "            print(model_name, 'for fold', fold, 'exists. Loading the saved model...')\n",
    "            json_file = open(model_file_path, 'r')\n",
    "            loaded_model_json = json_file.read()\n",
    "            json_file.close()\n",
    "            model = model_from_json(loaded_model_json)\n",
    "            model.load_weights(weight_file_path)\n",
    "        else:\n",
    "            print(model_name, 'for fold', fold, 'does not exist. Training starts...')\n",
    "            if not os.path.exists(model_folder): os.mkdir(model_folder)\n",
    "            \n",
    "            x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "            x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
    "            class_number = y_train.shape[1]\n",
    "\n",
    "            print('Creating LSTM_6 for fold', fold, '...')\n",
    "            model = Sequential()\n",
    "            model.add(CuDNNLSTM(60, input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "            model.add(CuDNNLSTM(60, return_sequences=True))\n",
    "            model.add(CuDNNLSTM(60, return_sequences=False))\n",
    "            model.add(Dense(y_train.shape[1],activation='softmax'))\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            model.summary()\n",
    "\n",
    "            checkpoint_path = os.path.join(model_folder, 'weight.E{epoch:02d}.h5')\n",
    "            checkpointer = ModelCheckpoint(filepath=checkpoint_path, verbose=0)\n",
    "            monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3,\n",
    "                                    patience=5, verbose=2, mode='auto')\n",
    "\n",
    "            start_epoch = 0\n",
    "            for file in os.listdir(model_folder):\n",
    "                if file.endswith('.h5'): start_epoch += 1\n",
    "\n",
    "            if start_epoch > 0:\n",
    "                model.load_weights(os.path.join(model_folder, file))\n",
    "                print('Training resumes from epoch #', start_epoch)\n",
    "            else:\n",
    "                print('Training starts from scratch...')\n",
    "\n",
    "            history = model.fit(x_train, y_train, validation_data=(x_val,y_val),\n",
    "                                callbacks=[checkpointer,monitor], initial_epoch=start_epoch,\n",
    "                                verbose=2, epochs=1)\n",
    "\n",
    "            print(history.history)\n",
    "            # plot and save history for accuracy\n",
    "            plt.figure()\n",
    "            plt.plot(history.history['accuracy'])\n",
    "            plt.plot(history.history['val_accuracy'])\n",
    "            plt.title('model accuracy')\n",
    "            plt.ylabel('accuracy')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['training', 'validation'], loc='upper left')\n",
    "            plt.savefig(os.path.join(model_folder, 'accuracy.png'))\n",
    "            # plot and save history for loss\n",
    "            plt.figure()\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.plot(history.history['val_loss'])\n",
    "            plt.title('model loss')\n",
    "            plt.ylabel('loss')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(['training', 'validation'], loc='upper right')\n",
    "            plt.savefig(os.path.join(model_folder, 'loss.png'))\n",
    "\n",
    "            print('Training completed. Saving the model and the final weights...')\n",
    "            with open(model_file_path, \"w\") as json_file: json_file.write(model.to_json())\n",
    "            model.save_weights(weight_file_path)\n",
    "            if experiment_num == 3: np.save(features_path, random_indices)\n",
    "        \n",
    "        print('Testing the', model_name, 'for fold', fold, '...')\n",
    "        result_folder = os.path.join(results_folder, model_name + '_' + str(fold))        \n",
    "        if not os.path.exists(result_folder): os.mkdir(result_folder)\n",
    "\n",
    "        y_test_all, y_test_uniform = labels[~mask], labels[test_indices[fold-1]]\n",
    "        \n",
    "        test_array = [(x_test_uniform, y_test_uniform), (x_test_all, y_test_all)]\n",
    "        test_names = ['uniform', 'complete']\n",
    "        \n",
    "        for i in range(2):\n",
    "            name = test_names[i]\n",
    "            pred_path = os.path.join(result_folder, 'pred_' + name + '.npy' )\n",
    "            y_test = label_encoder.transform(test_array[i][1])\n",
    "            y_test = one_hot_encoder.transform(y_test.reshape(-1,1))\n",
    "            y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "            if os.path.exists(pred_path):\n",
    "                print('Loading the existing predictions for model', model_name + ', fold', fold, 'and test', name + '...')\n",
    "                pred = np.load(pred_path)\n",
    "                if experiment_num == 2:\n",
    "                    if tp is None:\n",
    "                        tp = np.load(tim_perf_path, allow_pickle=True)\n",
    "                    time_spent = tp[i][model_name][fold-1]\n",
    "                \n",
    "            else:\n",
    "                print('Predicting the labels for model', model_name + ', fold', fold, 'and test', name + '...')\n",
    "\n",
    "                if experiment_num == 2: start = process_time()\n",
    "                x_test = minmax_scaler.transform(test_array[i][0])\n",
    "                x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "\n",
    "                pred = model.predict(x_test)\n",
    "                pred = np.argmax(pred, axis=1)\n",
    "                if experiment_num == 2:\n",
    "                    end = process_time()\n",
    "                    time_spent = end - start\n",
    "                np.save(pred_path, pred)\n",
    "\n",
    "            if model_name not in overall_accuracy[i]:\n",
    "                overall_accuracy[i][model_name] = [[],[],[],[],[]]\n",
    "            overall_accuracy[i][model_name][fold-1] = metrics.accuracy_score(y_test, pred)\n",
    "\n",
    "            if model_name not in conf_matrix[i]:\n",
    "                conf_matrix[i][model_name] = [[],[],[],[],[]]\n",
    "            conf_m = metrics.confusion_matrix(y_test, pred)\n",
    "            conf_matrix[i][model_name][fold-1] = conf_m\n",
    "\n",
    "            if model_name not in category_accuracy[i]:\n",
    "                category_accuracy[i][model_name] = [[],[],[],[],[]]\n",
    "            category_accuracy[i][model_name][fold-1] = conf_m.diagonal()/conf_m.sum(axis=1)\n",
    "            \n",
    "            if experiment_num == 2:\n",
    "                if model_name not in time_performance[i]:\n",
    "                    time_performance[i][model_name] = [[],[],[],[],[]]\n",
    "                time_performance[i][model_name][fold-1] = time_spent\n",
    "        \n",
    "    del x_train, y_train, model\n",
    "\n",
    "    np.save(acc_path, overall_accuracy)\n",
    "    np.save(conf_path, conf_matrix)\n",
    "    np.save(cat_acc_path, category_accuracy)\n",
    "    if experiment_num == 2: np.save(tim_perf_path, time_performance)\n",
    "    print('Results are saved.')\n",
    "print('All model training and tests for feature analysis are completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
